{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y4nCLborD8S",
        "outputId": "a8689588-760f-439d-d3bd-4344c1407ec9"
      },
      "outputs": [],
      "source": [
        "#!pip install    datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_-Cx6nTRBmy",
        "outputId": "bff75cda-ab6a-4ec4-e6ed-c5c0f4668566"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "cannot load library '/Users/aziiz/miniforge3/lib/python3.9/site-packages/_soundfile_data/libsndfile.dylib': dlopen(/Users/aziiz/miniforge3/lib/python3.9/site-packages/_soundfile_data/libsndfile.dylib, 0x0002): tried: '/Users/aziiz/miniforge3/lib/python3.9/site-packages/_soundfile_data/libsndfile.dylib' (no such file)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/soundfile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sndfile library not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0m_snd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_libname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: cannot load library '/Users/aziiz/miniforge3/bin/../lib/libsndfile.dylib': dlopen(/Users/aziiz/miniforge3/bin/../lib/libsndfile.dylib, 0x0002): Library not loaded: @rpath/libvorbis.0.4.9.dylib\n  Referenced from: /Users/aziiz/miniforge3/lib/libsndfile.1.0.31.dylib\n  Reason: tried: '/Users/aziiz/miniforge3/lib/libvorbis.0.4.9.dylib' (no such file), '/Users/aziiz/miniforge3/lib/libvorbis.0.4.9.dylib' (no such file), '/Users/aziiz/miniforge3/lib/libvorbis.0.4.9.dylib' (no such file), '/Users/aziiz/miniforge3/lib/libvorbis.0.4.9.dylib' (no such file), '/Users/aziiz/miniforge3/lib/python3.9/site-packages/../../libvorbis.0.4.9.dylib' (no such file), '/Users/aziiz/miniforge3/lib/libvorbis.0.4.9.dylib' (no such file), '/Users/aziiz/miniforge3/bin/../lib/libvorbis.0.4.9.dylib' (no such file), '/usr/local/lib/libvorbis.0.4.9.dylib' (no such file), '/usr/lib/libvorbis.0.4.9.dylib' (no such file)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/wb/wwv1wvqj71bddn4mzdyb1srw0000gn/T/ipykernel_15085/883384097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWav2Vec2Processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHubertModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2Processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/hubert-large-ls960-ft\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/soundfile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     _snd = _ffi.dlopen(_os.path.join(\n\u001b[0m\u001b[1;32m    163\u001b[0m         _path, '_soundfile_data', _libname))\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: cannot load library '/Users/aziiz/miniforge3/lib/python3.9/site-packages/_soundfile_data/libsndfile.dylib': dlopen(/Users/aziiz/miniforge3/lib/python3.9/site-packages/_soundfile_data/libsndfile.dylib, 0x0002): tried: '/Users/aziiz/miniforge3/lib/python3.9/site-packages/_soundfile_data/libsndfile.dylib' (no such file)"
          ]
        }
      ],
      "source": [
        "from transformers import Wav2Vec2Processor, HubertModel\n",
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
        "model = HubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du4fKd32RBkW",
        "outputId": "36a08fbd-ff51-49d1-e147-b1eabc8f4952"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Reusing dataset librispeech_asr_dummy (/root/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b/cache-b95089e59d8137ae.arrow\n"
          ]
        }
      ],
      "source": [
        "def map_to_array(batch):\n",
        "    speech, _ = sf.read(batch[\"file\"])\n",
        "    batch[\"speech\"] = speech\n",
        "    return batch\n",
        "\n",
        "\n",
        "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
        "ds = ds.map(map_to_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhPJXyQlSwcc",
        "outputId": "4dd4eda9-6f89-4e8d-c9b5-6f5bc4b538a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
          ]
        }
      ],
      "source": [
        "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\").input_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDgAIaKDSgx2",
        "outputId": "baeecde1-a741-4d82-b1ab-debe95b5c0c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0386, 0.0337, 0.0322,  ..., 0.0070, 0.0095, 0.0169]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6XgL5GgjSgvK"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T9JIQGLnSgl0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V6K11XHmRBhf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "\n",
        "    processor: Wav2Vec2Processor\n",
        "    padding: Union[bool, str] = True\n",
        "    max_length: Optional[int] = None\n",
        "    max_length_labels: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    pad_to_multiple_of_labels: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features) :\n",
        "        # split inputs and labels since they have to be of different lenghts and need\n",
        "        # different padding methods\n",
        "        input_features = [{\"input_values\": feature } for feature in features]\n",
        "     \n",
        "        batch = self.processor.pad(\n",
        "            input_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )  \n",
        "       \n",
        "        batch[\"mask_time_indices\"] = [ self.get_mask(i)  for i in batch[\"input_values\"] ]\n",
        "\n",
        "        return batch\n",
        "\n",
        "\n",
        "    def get_mask (self , input_values):\n",
        "     \n",
        "      batch_size, raw_sequence_length = 1 , input_values.shape[0]\n",
        "      sequence_length = model._get_feat_extract_output_lengths(raw_sequence_length)\n",
        "      mask_time_indices = _compute_mask_indices((batch_size, sequence_length), mask_prob=0.2, mask_length=2)\n",
        "      mask_time_indices = torch.tensor(mask_time_indices, device=input_values.device, dtype=torch.long)\n",
        "\n",
        "      return  mask_time_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "avxSTwULRBbw"
      },
      "outputs": [],
      "source": [
        "dataCollactor = DataCollatorCTCWithPadding(processor=processor, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OBmlkulXRBY4"
      },
      "outputs": [],
      "source": [
        "data =dataCollactor(ds[\"speech\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad-LeFxadFTg",
        "outputId": "d659c10d-438c-4c55-c6a0-c98caec5d639"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_values': tensor([[ 2.3804e-03,  2.0752e-03,  1.9836e-03,  ...,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [-1.5259e-04, -9.1553e-05, -1.8311e-04,  ...,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [-6.7139e-04,  6.1035e-05,  5.1880e-04,  ...,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        ...,\n",
              "        [-3.0518e-05, -1.8311e-04, -2.1362e-04,  ...,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [-3.9673e-04, -3.0518e-05,  8.8501e-04,  ...,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00],\n",
              "        [ 1.8311e-03, -2.1362e-04, -6.1035e-05,  ...,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32), 'mask_time_indices': [tensor([[0, 0, 0,  ..., 1, 1, 1]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 1, 1, 1]]), tensor([[0, 1, 1,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 1, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[1, 1, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 1,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 1, 1, 0]]), tensor([[0, 0, 1,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[1, 1, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 1, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 1, 1]]), tensor([[0, 0, 0,  ..., 1, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 1, 1,  ..., 1, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[1, 1, 0,  ..., 1, 1, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 1, 1,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 1,  ..., 1, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 1, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 1, 1]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 1,  ..., 0, 0, 0]]), tensor([[1, 1, 0,  ..., 0, 1, 1]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 1, 1, 0]]), tensor([[0, 0, 1,  ..., 0, 1, 1]]), tensor([[0, 0, 0,  ..., 1, 1, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 1, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[1, 1, 0,  ..., 0, 0, 0]]), tensor([[1, 1, 0,  ..., 1, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 1, 1]]), tensor([[0, 1, 1,  ..., 1, 1, 0]]), tensor([[1, 1, 1,  ..., 0, 0, 0]]), tensor([[0, 0, 1,  ..., 0, 1, 1]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[1, 1, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 1,  ..., 1, 1, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 1, 1, 1]]), tensor([[0, 0, 0,  ..., 1, 1, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0]])]}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7fIme69BRBNR"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader , Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VoSYAzi2pwPS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XM8bypBhcliS"
      },
      "outputs": [],
      "source": [
        "# Need to override __init__, __len__, __getitem__\n",
        "# as per datasets requirement\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "      self.data =data\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.data[\"input_values\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "      input_values = self.data[\"input_values\"][idx]\n",
        "      attention_mask = self.data[\"attention_mask\"][idx]\n",
        "      mask_time_indices = self.data[\"mask_time_indices\"][idx]\n",
        "\n",
        "      \n",
        "      return {'input_values':input_values ,\n",
        "              'attention_mask': attention_mask,\n",
        "              'mask_time_indices':mask_time_indices \n",
        "              }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ntXhL17YcPdw"
      },
      "outputs": [],
      "source": [
        "costum_dataset = CustomDataset(data) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dVg2Qdi9qi4n"
      },
      "outputs": [],
      "source": [
        "train_loader =DataLoader(costum_dataset , batch_size = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n7A9-Mdxqiz_"
      },
      "outputs": [],
      "source": [
        "data = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD4JakCTcPZy",
        "outputId": "cb87c5c4-385b-4550-e37a-48ba0e050307"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32),\n",
              " 'input_values': tensor([[ 2.3804e-03,  2.0752e-03,  1.9836e-03,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00],\n",
              "         [-1.5259e-04, -9.1553e-05, -1.8311e-04,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00],\n",
              "         [-6.7139e-04,  6.1035e-05,  5.1880e-04,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00],\n",
              "         [-4.5776e-04, -3.9673e-04, -4.8828e-04,  ...,  0.0000e+00,\n",
              "           0.0000e+00,  0.0000e+00]]),\n",
              " 'mask_time_indices': tensor([[[0, 0, 0,  ..., 1, 1, 1]],\n",
              " \n",
              "         [[0, 0, 0,  ..., 0, 0, 0]],\n",
              " \n",
              "         [[0, 0, 0,  ..., 1, 1, 1]],\n",
              " \n",
              "         [[0, 1, 1,  ..., 0, 0, 0]]])}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ydiMG_-dRBH-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BqgQEmdRBFP",
        "outputId": "7ca5b8f3-12b7-42d2-db7b-a7995ef5c1c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0024, 0.0021, 0.0020,  ..., 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"input_values\"][0].view(1,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS_Fv7Q1RBCn"
      },
      "outputs": [],
      "source": [
        "output = model (data[\"input_values\"][0].view(1,-1) ,attention_mask=data[\"attention_mask\"][0]  , mask_time_indices=data[\"mask_time_indices\"][0]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "MgcAil9-RBAI",
        "outputId": "5fcc910b-66ce-415d-8172-7e3070d082b5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c5d84736ba45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7-joXwPRA9a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncb25-aWRA6r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd61gsjqRA39"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtZpgXbvRA1W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpldnDxARAy1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voWY0pc7RAwW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb7kSMd2RAto"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5HoZsa-RArS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrvLwMZ8RAor"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkP-YxyJRAmE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FLY56obRAjl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWiLC-d8RAgm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qyCVCyPvr1MQ"
      },
      "outputs": [],
      "source": [
        "import librosa \n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyG23tdRtDN2",
        "outputId": "14fd1dd0-7cb7-4b9f-8b78-e31790a6382b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/hubert-large-ls960-ft were not used when initializing HubertModel: ['lm_head.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "WARNING:datasets.builder:Reusing dataset librispeech_asr_dummy (/root/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b/cache-b95089e59d8137ae.arrow\n"
          ]
        }
      ],
      "source": [
        "from transformers import Wav2Vec2Processor, HubertModel\n",
        "from datasets import load_dataset\n",
        "import soundfile as sf\n",
        "\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
        "model = HubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
        "\n",
        "\n",
        "def map_to_array(batch):\n",
        "    speech, _ = sf.read(batch[\"file\"])\n",
        "    batch[\"speech\"] = speech\n",
        "    return batch\n",
        "\n",
        "\n",
        "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
        "ds = ds.map(map_to_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "017eoS8Zu9MP",
        "outputId": "c65f6596-e814-4c1e-cd98-43718543ba3e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "input_values = processor(ds[\"speech\"][0], return_tensors=\"pt\")  # Batch size 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEoxrF-EQ2ZX",
        "outputId": "d5f73acf-7241-4b40-fb59-8f4b82c9a21f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_values': tensor([[0.0386, 0.0337, 0.0322,  ..., 0.0070, 0.0095, 0.0169]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "VVrrSUqqQfwt"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  logits = model(**input_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXH7EmVnQftm",
        "outputId": "e9322121-b46a-4eb9-f0ae-67cffa655afa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaseModelOutput([('last_hidden_state',\n",
              "                  tensor([[[ 1.0640e-01,  4.2005e-01,  4.7533e-01,  ...,  1.9920e-01,\n",
              "                            -2.1367e-01, -6.6571e-02],\n",
              "                           [ 7.9912e-02,  3.8839e-01,  5.8362e-01,  ...,  2.0243e-01,\n",
              "                            -1.8895e-01,  1.2788e-01],\n",
              "                           [ 8.1471e-02,  7.1193e-01, -3.9914e-02,  ..., -2.0461e-01,\n",
              "                            -2.5948e-01, -2.1146e-01],\n",
              "                           ...,\n",
              "                           [ 1.1822e-01,  3.5617e-01,  4.9074e-01,  ...,  1.6533e-01,\n",
              "                            -3.3429e-01,  2.4379e-01],\n",
              "                           [-3.8053e-04,  4.1052e-01,  4.0782e-01,  ...,  1.7386e-01,\n",
              "                            -3.5163e-01,  1.6484e-01],\n",
              "                           [-4.2190e-02,  4.1631e-01,  2.8498e-01,  ...,  2.0109e-01,\n",
              "                            -3.4026e-01,  1.4069e-03]]]))])"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "PwzHGkEuO-Yu"
      },
      "outputs": [],
      "source": [
        "import  numpy.ma  as ma "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "1-gH0E1UPi2i"
      },
      "outputs": [],
      "source": [
        "import numpy as np "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GJ8qVyWPv4D",
        "outputId": "75ff261c-e514-4392-91cc-4b45812177a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "        0, 0, 1, 1])"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask_time_indices[-1] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "2A13yxkWPb-N"
      },
      "outputs": [],
      "source": [
        "arr =np.random.rand(1, 120000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Grf63nRtO-Wq",
        "outputId": "4f8afeed-5251-4135-bc46-c418be087f27"
      },
      "outputs": [
        {
          "ename": "MaskError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMaskError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-cdd746ca819d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaskArr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_time_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, mask, dtype, copy, subok, ndmin, fill_value, keep_mask, hard_mask, shrink, order)\u001b[0m\n\u001b[1;32m   2906\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Mask and data not compatible: data size is %i, \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2907\u001b[0m                           \u001b[0;34m\"mask size is %i.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2908\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mMaskError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2909\u001b[0m                 \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2910\u001b[0m             \u001b[0;31m# Set the mask to the new value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaskError\u001b[0m: Mask and data not compatible: data size is 120000, mask size is 292."
          ]
        }
      ],
      "source": [
        "maskArr = ma.masked_array(arr, mask=mask_time_indices[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgDCfI9iO-UM",
        "outputId": "e8178d4e-1bf8-4a0d-c183-ee9654301f88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0386, 0.0337, 0.0322,  ..., 0.0070, 0.0095, 0.0169]])"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3n38-YYO-Rf",
        "outputId": "fd0ee557-8ae3-4f87-b3f5-3fb033ffef3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "         1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "         1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "         0, 0, 1, 1]])"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mask_time_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "UO043DTKNAny"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "kDIGLJjsLufX"
      },
      "outputs": [],
      "source": [
        "batch_size, raw_sequence_length = input_values.shape\n",
        "sequence_length = model._get_feat_extract_output_lengths(raw_sequence_length)\n",
        "mask_time_indices = _compute_mask_indices((batch_size, sequence_length), mask_prob=0.2, mask_length=2)\n",
        "mask_time_indices = torch.tensor(mask_time_indices, device=input_values.device, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "NAej1E6yzn9h",
        "outputId": "6229f691-57d2-45cd-a372-fce537e019ac"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-340645836eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_time_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_time_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/hubert/modeling_hubert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask_hidden_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_time_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_time_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/hubert/modeling_hubert.py\u001b[0m in \u001b[0;36m_mask_hidden_states\u001b[0;34m(self, hidden_states, mask_time_indices, attention_mask)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask_time_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;31m# apply SpecAugment along time axis with given mask_time_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_time_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_spec_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_time_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             mask_time_indices = _compute_mask_indices(\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
          ]
        }
      ],
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_values, mask_time_indices=mask_time_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "qrlLXEH7vP4z",
        "outputId": "dd952963-19f0-4af8-e771-9aebe55d205f"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-7570803910a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_time_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_time_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/hubert/modeling_hubert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask_hidden_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_time_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_time_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/hubert/modeling_hubert.py\u001b[0m in \u001b[0;36m_mask_hidden_states\u001b[0;34m(self, hidden_states, mask_time_indices, attention_mask)\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask_time_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;31m# apply SpecAugment along time axis with given mask_time_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_time_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_spec_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_time_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             mask_time_indices = _compute_mask_indices(\n",
            "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
          ]
        }
      ],
      "source": [
        "output = model(input_values, mask_time_indices=mask_time_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw7op0o3vP2Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQA6GhuzvPzV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdpc_s1zvPwf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8gbc4GLtDLP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJC_C3QysD0z",
        "outputId": "380eb917-12e7-4ea3-dbf8-a1fe47e3f295"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "WARNING:datasets.builder:Reusing dataset librispeech_asr_dummy (/root/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n",
            "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoFeatureExtractor, Wav2Vec2ForPreTraining\n",
        "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices\n",
        "from datasets import load_dataset\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
        "model = Wav2Vec2ForPreTraining.from_pretrained(\"facebook/wav2vec2-base\")\n",
        "\n",
        "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
        "input_values = feature_extractor(ds[0][\"audio\"][\"array\"], return_tensors=\"pt\").input_values  # Batch size 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "5-D2VzqWsJX6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# compute masked indices\n",
        "batch_size, raw_sequence_length = input_values.shape\n",
        "sequence_length = model._get_feat_extract_output_lengths(raw_sequence_length)\n",
        "mask_time_indices = _compute_mask_indices((batch_size, sequence_length), mask_prob=0.2, mask_length=2)\n",
        "mask_time_indices = torch.tensor(mask_time_indices, device=input_values.device, dtype=torch.long)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_values, mask_time_indices=mask_time_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bkQDIw8sJuD",
        "outputId": "1199e52d-6328-4255-89d5-05bbc57d47c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Wav2Vec2ForPreTrainingOutput([('projected_states',\n",
              "                               tensor([[[-0.2813,  2.6754, -0.6393,  ..., -0.0373,  0.0163,  0.0333],\n",
              "                                        [ 1.5432,  2.1354, -0.3621,  ..., -0.7258,  0.5428, -1.0003],\n",
              "                                        [-0.9096,  3.5332,  0.7381,  ..., -2.7142, -3.3135,  0.9322],\n",
              "                                        ...,\n",
              "                                        [-0.8724,  0.5275,  1.1799,  ..., -0.0055, -1.1114,  0.4923],\n",
              "                                        [-1.0138, -1.4169,  0.9391,  ..., -0.6488, -1.2267, -0.9506],\n",
              "                                        [-1.0640, -1.1501,  1.5004,  ..., -0.5585, -0.9427,  1.0709]]])),\n",
              "                              ('projected_quantized_states',\n",
              "                               tensor([[[ 0.3261,  0.9365,  0.0114,  ..., -0.1760, -0.4141,  0.4569],\n",
              "                                        [ 0.4270,  0.7415,  0.0088,  ..., -0.1571, -0.2923,  0.3007],\n",
              "                                        [-0.0186,  0.5143,  0.2091,  ..., -0.5655, -0.5427,  0.3495],\n",
              "                                        ...,\n",
              "                                        [-0.3023,  0.5023,  0.3194,  ..., -0.4565, -0.5182,  0.1581],\n",
              "                                        [ 0.0962,  0.1694,  0.1970,  ..., -0.5435,  0.1267,  0.1081],\n",
              "                                        [-0.1448,  0.2493,  0.1509,  ..., -0.7169, -0.2876,  0.4087]]])),\n",
              "                              ('codevector_perplexity', tensor(68.0961))])"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XObPQGEBOYh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# compute cosine similarity between predicted (=projected_states) and target (=projected_quantized_states)\n",
        "cosine_sim = torch.cosine_similarity(outputs.projected_states, outputs.projected_quantized_states, dim=-1)\n",
        "\n",
        "# show that cosine similarity is much higher than random\n",
        "cosine_sim[mask_time_indices.to(torch.bool)].mean() > 0.5\n",
        "\n",
        "# for contrastive loss training model should be put into train mode\n",
        "model = model.train()\n",
        "loss = model(input_values, mask_time_indices=mask_time_indices).loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "8q0XbC6QBOVf"
      },
      "outputs": [],
      "source": [
        "from transformers import HubertModel, HubertConfig\n",
        "\n",
        "# Initializing a Hubert facebook/hubert-base-ls960 style configuration\n",
        "configuration = HubertConfig()\n",
        "\n",
        "# Initializing a model from the facebook/hubert-base-ls960 style configuration\n",
        "model = HubertModel(configuration)\n",
        "\n",
        "# Accessing the model configuration\n",
        "configuration = model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "XNHTPC9mBOS4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43hMrSH9BOQf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled203.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "151447786cdc174c34524fe3511c9399d0af365a749276a2759e8b6c9221e675"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
